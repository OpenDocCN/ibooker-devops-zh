# 第二十一章：多集群应用部署

本书共有二十章，应该明白 Kubernetes 可以是一个复杂的主题，当然，希望如果您已经读到这里，它比起初要清晰些。考虑到在单个 Kubernetes 集群中构建和运行应用程序的复杂性，为什么要增加设计和部署应用程序到多个集群的复杂性呢？

事实上，现实世界的需求意味着大多数应用程序需要进行多集群应用部署。这有许多原因，很可能您的应用程序至少符合其中一个要求。

第一个要求是冗余和弹性的需求。无论是在云端还是本地，单个数据中心通常是一个单一故障域。无论是猎人使用光纤电缆作为靶子的练习，还是冰风暴导致的停电，或者仅仅是软件发布的失败，部署到单个位置的任何应用程序都可能完全失败，使用户无法获得任何补救措施。在许多情况下，单个 Kubernetes 集群都与单个位置绑定，因此是一个单一故障域。

在某些情况下，特别是在云环境中，Kubernetes 集群被设计为*区域性*。区域性集群跨越多个独立区域，因此对于之前描述的基础设施问题具有弹性。因此很容易认为这样的区域性集群足以保证弹性，除了 Kubernetes 本身可能成为单点故障的事实。任何单个 Kubernetes 集群都与特定版本的 Kubernetes 绑定（例如，1.21.3），升级集群可能会导致应用程序出现问题。有时 Kubernetes 会弃用 API 或更改这些 API 的行为。这些变更不频繁，Kubernetes 社区会提前进行沟通确保变更顺利进行。此外，尽管经过大量测试，但偶尔仍会在发布版本中引入错误。尽管任何一个问题影响您的应用程序的可能性不大，但在大多数应用程序的生命周期（几年）内，您的应用程序很可能会受到某种程度的影响。对于大多数应用程序来说，这是不可接受的风险。

除了弹性要求外，多集群部署的另一个强大驱动因素是对区域关联的业务或应用需求。例如，游戏服务器需要靠近玩家以减少网络延迟并提高游戏体验。其他应用可能受到法律或监管要求的限制，要求数据位于特定的地理区域内。由于任何 Kubernetes 集群都与特定位置绑定，这些应用部署到特定地理位置的需求意味着应用必须跨越多个集群。

最后，尽管在单个集群中有多种隔离用户的方法（例如命名空间、RBAC、节点池——为不同能力或工作负载组织的 Kubernetes 节点集合），但 Kubernetes 集群仍然基本上是一个单一的合作空间。对于一些团队和产品来说，不同团队甚至会因为意外影响他们的应用的风险不值得，他们宁愿承担管理多个集群的复杂性。

到了这一点，你可以看到，无论你的应用程序如何，很可能现在或在不久的将来，你的应用程序都需要跨多个集群。本章的其余部分将帮助你理解如何实现这一点。

# 在你开始之前

在考虑迁移到多集群部署之前，确保单个集群部署具备正确的基础架构至关重要。每个人对他们的设置都有一份必须做的清单，但是这些捷径和问题在多集群部署中被放大。同样地，在拥有 10 个集群时，修复基础设施中的问题会变得十分困难。此外，如果增加额外的集群需要付出显著的额外工作，你可能会抗拒增加额外的集群，尽管（因为前面提到的种种原因）这对你的应用来说是正确的做法。

当我们说“基础架构”时，我们指的是什么？正确的自动化是最重要的部分。重要的是，这不仅包括部署应用程序的自动化，还包括创建和管理集群本身的自动化。当你只有一个集群时，它从定义上来说是一致的。然而，当你增加集群时，你增加了集群中各个组件版本不一致的可能性。你可能会拥有不同版本的 Kubernetes、不同版本的监控和日志代理，甚至是容器运行时的基本差异。所有这些变化都会使你的生活更加困难。基础设施的差异使得你的系统变得“更加奇怪”。在一个集群中获得的知识并不能转移到其他集群，有时因为这种差异性，问题似乎会在某些地方随机发生。保持稳定基础的一个最重要的部分就是确保所有集群的一致性。

实现这种一致性的唯一途径是自动化。你可能会想，“我总是以这种方式创建集群”，但经验告诉我们，这并不正确。下一章将详细讨论基础设施即代码对于管理你的应用程序的价值，但同样适用于管理你的集群。不要使用 GUI 或 CLI 工具来创建你的集群。起初通过源代码控制和 CI/CD 推送所有更改可能看起来很麻烦，但稳定的基础会带来显著的回报。

部署到您的集群中的基础组件也是如此。这些组件包括监控、日志记录和安全扫描器，在部署任何应用程序之前都必须存在。这些工具还需要使用 Helm 等基础设施即代码工具进行管理，并使用自动化进行部署。

超越集群形状的内容，还有其他必要的一致性方面。首先是为所有集群使用单一身份系统。虽然 Kubernetes 支持简单的基于证书的身份验证，但我们强烈建议使用与全球身份提供者（如 Azure Active Directory 或任何其他支持 OpenID Connect 的身份提供者）集成。确保每个人访问所有集群时都使用相同的身份是维护安全最佳实践并避免危险行为（如共享证书）的关键部分。此外，大多数这些身份提供者还提供额外的安全控制，如双因素身份验证，可以增强集群的安全性。

就像身份验证一样，确保集群的一致访问控制也非常关键。在大多数云平台中，这意味着使用基于云的 RBAC，在这种情况下，RBAC 角色和绑定存储在中央云位置，而不是在集群本身。在单一位置定义 RBAC 可以防止诸如在某个集群中留下权限或未能向某个单一集群添加权限等错误。不幸的是，如果要为本地集群定义 RBAC，则情况比身份验证要复杂得多。有一些解决方案（例如，用于 Kubernetes 的 Azure Arc）可以为本地集群提供 RBAC，但如果您的环境中没有此类服务，则在源代码控制中定义 RBAC 并使用基础设施即代码将规则应用于所有集群可以确保跨整个部署中应用一致的特权。

同样地，当您考虑为集群定义策略时，定义这些策略并在单一位置上具有用于查看所有集群符合状态的单一仪表板非常关键。与 RBAC 一样，此类全局服务通常通过您的云提供商提供，但对于本地部署，选项有限。同样可以使用基础设施即代码工具来帮助填补此差距，并确保您可以在单一位置定义您的策略。

就像设置正确的单元测试和构建基础设施对应用程序开发至关重要一样，为管理多个 Kubernetes 集群设置正确的基础设施为在广泛的基础设施群中稳定部署应用程序奠定了基础。在接下来的部分中，我们将讨论如何构建您的应用程序以在多集群环境中成功运行。

# 从顶部开始使用负载平衡方法

一旦开始考虑将应用部署到多个位置，就变得必要考虑用户如何访问它。通常通过域名来实现这一点（例如，my.company.com）。虽然我们将花费大量时间讨论如何构建你的应用程序以在多个位置运行，但更重要的起点是如何实施访问。这是因为显然使人们能够使用你的应用程序是至关重要的，但也因为设计人们如何访问你的应用程序可以提高你在意外负载或故障情况下快速响应和重新路由流量的能力。

访问你的应用程序始于一个域名。这意味着你的多集群负载均衡策略的开始是一个 DNS 查询。这个 DNS 查询是你负载均衡策略的第一个选择。在许多传统的负载均衡方法中，这个 DNS 查询被用于将流量路由到特定的位置。这通常被称为“GeoDNS”。在 GeoDNS 中，DNS 查询返回的 IP 地址与客户端的物理位置相关联。IP 地址通常是离客户端最近的区域集群。

虽然 GeoDNS 在许多应用中仍然流行，并且对于本地应用可能是唯一可行的方法，但它有一些缺点。第一个缺点是 DNS 在互联网的各个地方都有缓存，虽然你可以设置 DNS 查询的生存时间（TTL），但在追求更高性能时，许多地方会忽略这个 TTL。在稳定状态下运行时，这种缓存并不是什么大问题，因为 DNS 通常是相当稳定的，无论 TTL 是多少。然而，当你需要将流量从一个集群移动到另一个集群时，比如响应特定数据中心的故障时，这就成为一个非常大的问题。在这种紧急情况下，DNS 查询被缓存的事实可能会显著延长停机的持续时间和影响。此外，由于 GeoDNS 根据客户端的 IP 地址猜测你的物理位置，当许多不同的客户端从同一防火墙 IP 地址出口其流量时，尽管它们位于许多不同的地理位置，GeoDNS 经常会感到困惑并猜测错误的位置。

用于选择你的集群的另一种替代方法是一种称为*任播*的负载均衡技术。使用任播网络，单个静态 IP 地址通过核心路由协议从互联网的多个位置进行广告。传统上我们认为 IP 地址映射到单个机器，但是使用任播网络，IP 地址实际上是一个虚拟 IP 地址，根据你的网络位置被路由到不同的位置。你的流量根据网络性能的距离而不是地理距离被路由到“最近”的位置。任播网络通常能产生更好的结果，但并不总是在所有环境中都可用。

在设计负载平衡时的最后一个考虑因素是负载平衡是在 TCP 层还是 HTTP 层进行的。到目前为止，我们只讨论了 TCP 级别的负载平衡，但对于基于 Web 的应用程序来说，在 HTTP 层进行负载平衡有显著的好处。如果您正在编写基于 HTTP 的应用程序（大多数应用程序都是这样的），那么使用全局 HTTP 感知负载均衡器使您能够了解更多客户端通信的细节。例如，您可以根据浏览器中设置的 cookie 做出负载平衡决策。此外，了解协议的负载均衡器可以做出更智能的路由决策，因为它看到每个 HTTP 请求，而不仅仅是通过 TCP 连接的字节流。

无论您选择哪种方法，最终您的服务位置都将从全局 DNS 端点映射到代表服务入口点的一组区域 IP 地址。这些 IP 地址通常是您在本书前几章中了解到的 Kubernetes 服务或入口资源的 IP 地址。一旦用户流量到达该端点，它将根据您的应用程序设计流经您的集群。

# 构建多集群应用程序

一旦您解决了负载平衡问题，设计多集群应用程序的下一个挑战是考虑状态。理想情况下，您的应用程序不需要状态，或者所有状态都是只读的。在这种情况下，您几乎不需要做任何事情来支持多个集群部署。您的应用程序可以单独部署到每个集群中，顶部添加一个负载均衡器，您的多集群部署就完成了。不幸的是，对于大多数应用程序来说，存在必须以一致方式在应用程序副本之间管理的状态。如果您没有正确处理状态，您的用户将得到一个令人困惑且有缺陷的体验。

要理解复制状态如何影响用户体验，让我们以一个简单的零售商店为例。很明显，如果您只在多个集群中的一个中存储客户订单，当他们的请求移到不同的区域时，客户可能会无法看到他们的订单，无论是因为负载平衡还是因为他们实际上移动了地理位置。因此，用户的状态需要在各个区域之间复制。复制方法也可能影响客户体验，尽管这可能不那么明显。复制数据和客户体验的挑战被这个问题简洁地概括为：“我能读取我自己的写入吗？”看起来答案显而易见应该是“是的”，但实现这一点比看起来更难。例如，考虑一个在他们的电脑上下订单，然后立即在他们的手机上查看订单的客户。他们可能从完全不同的网络访问您的应用程序，因此可能会登陆到完全不同的集群上。用户关于他们能否查看刚刚下的订单的期望是一致性的一个例子。

一致性决定了您如何考虑复制数据。我们假设我们希望我们的数据是一致的；也就是说，无论我们从哪里读取数据，我们都能读取到相同的数据。但是，时间是一个复杂的因素：我们的数据必须多快才能保持一致？当数据不一致时，我们会得到任何错误指示吗？一致性有两种基本模型：*强一致性*保证了写操作直到成功复制之前都不会成功，而*最终一致性*则是写操作总是立即成功，并且只有在以后的某个时间点才保证成功复制。一些系统还允许客户端根据请求选择它们的一致性需求。例如，Azure Cosmos DB 实现了*有界一致性*，在这种最终一致性系统中对过期数据的一些保证。Google Cloud Spanner 使客户端能够指定他们愿意容忍旧数据读取，以换取更好的性能。

看起来每个人都会选择强一致性，因为它显然更容易理解，因为数据在任何地方都是相同的。但是强一致性是有代价的。在写入时保证复制需要更多的工作，当无法复制时，许多写入将失败。强一致性更昂贵，相对于最终一致性可以支持更少的并发事务。最终一致性更便宜，并且可以支持更高的写入负载，但对于应用程序开发者来说更为复杂，可能会向最终用户暴露一些边缘条件。许多存储系统仅支持单一并发模型。那些支持多个并发模型的存储系统要求在创建存储系统时指定。您选择的并发模型对应用程序的设计有重大影响，并且难以更改。因此，在为多个环境设计应用程序之前，选择一致性模型是一个重要的第一步。

###### 注意

部署和管理复制的有状态存储是一项复杂的任务，需要一个专门的团队具有领域专业知识来设置、维护和监控。您应该强烈考虑使用基于云的存储来进行复制数据存储，这样负担将由云提供商庞大的团队深度承担，而不是您自己的团队。在本地环境中，您还可以将存储的支持转移到专注于运行您选择的存储解决方案的公司。只有在大规模时，投资于构建自己的团队来管理存储才有意义。

一旦确定了存储层，下一步是构建应用程序设计。

## 复制的孤立体：最简单的跨区域模型

将您的应用程序简单复制到多个集群和多个区域的最简单方法只是将您的应用程序复制到每个区域。您的应用程序的每个实例都是一个完全相同的克隆，无论在哪个集群中运行，它看起来完全相同。由于顶部有一个负载均衡器分布客户请求，并且您已经在需要状态的地方实现了数据复制，您的应用程序不需要太多更改来支持这种模型。根据您选择的数据一致性模型，您需要处理的事实是数据在区域之间可能不会被快速复制，但是，特别是如果您选择强一致性，这不需要进行主要的应用程序重构。

当您以这种方式设计应用程序时，每个区域都是其自身的孤立体。它需要的所有数据都存在于该区域内，一旦请求进入该区域，它将完全由运行在那个集群中的容器提供服务。这在减少复杂性方面具有显著的好处，但像通常情况一样，这也是以效率为代价。

要理解分离式方法如何影响效率，请考虑一个分布在世界各地大量地理区域的应用程序，以便为其用户提供非常低的延迟。世界的现实是，某些地理区域有大量人口，而某些地区则人口较少。如果应用程序中每个簇的每个分离式都完全相同，那么每个分离式都必须大小适应最大的地理区域的需求。这样做的结果是，地区簇中应用程序的大多数副本都被大量超量配置，因此应用程序的成本效率较低。这种多余成本的明显解决方案是减少在较小地理区域使用的资源大小。虽然调整应用程序大小可能看起来很容易，但由于瓶颈或其他要求（例如，至少保持三个副本），这并不总是可行。

特别是将现有应用程序从单一集群转移到多集群时，复制的分离式设计是最简单的方法，但值得理解的是，它会带来成本，这些成本可能最初可以承受，但最终会要求重新设计您的应用程序。

## 分片：区域数据

当您的应用程序扩展时，您可能会遇到的一个痛点是，采用区域分离方法全球复制所有数据变得越来越昂贵，也越来越浪费。虽然为了可靠性复制数据是一件好事，但不太可能所有应用程序数据都需要在部署应用程序的每个集群中共同存在。大多数用户只会从少数几个地理区域访问您的应用程序。

此外，随着您的应用程序在全球范围内的增长，您可能会遇到关于数据本地性的法规和其他法律要求。根据用户的国籍或其他考虑因素，可能会存在关于存储用户数据位置的外部限制。这些要求的结合意味着最终您将需要考虑区域数据分片。在不同区域分片您的数据意味着您的应用程序在所有集群中并非所有数据都存在，这（显然）会影响您的应用程序设计。

以此作为例子，想象一下我们的应用程序部署到了六个区域集群（A、B、C、D、E、F）。我们将应用程序的数据集拆分为三个子集或*片段*（1、2、3）。

我们的数据片段部署可能如下所示：

|  | A | B | C | D | E | F |
| --- | --- | --- | --- | --- | --- | --- |
| 1 | ✓ | - | - | ✓ | - | - |
| 2 | - | ✓ | - | - | ✓ | - |
| 3 | - | - | ✓ | - | - | ✓ |

每个分片在两个区域中都有冗余性，但每个区域集群只能提供三分之一的数据。这意味着每当您需要访问数据时，您必须为服务添加额外的路由层。路由层负责确定请求是否需要发送到本地或跨区域数据分片。

尽管将这种数据路由作为链接到主应用程序的客户端库的一部分实现可能很诱人，但我们强烈建议将数据路由作为单独的微服务构建。引入新的微服务可能会增加复杂性，但实际上它引入了一个简化事物的抽象层。而不是您应用程序中的每个服务都担心数据路由，您只需一个服务封装这些关注点，而其他服务只需访问数据服务。将应用程序分解为独立的微服务提供了在多集群环境中显著灵活性。

## 更好的灵活性：微服务路由

当我们讨论多集群应用程序开发的区域隔离方法时，我们举了一个例子，说明它可能会降低部署的多集群应用程序的成本效率。但灵活性也会受到其他影响。在创建这种隔离时，您正在以更大规模创建容器和 Kubernetes 试图打破的单块体。此外，您正在强迫应用程序内的每个微服务同时扩展到相同数量的区域。

如果您的应用程序小而集中，这可能有道理，但随着服务变得越来越大，特别是当它们可能开始在多个应用程序之间共享时，单片式的多集群方法开始显著影响您的灵活性。如果集群是部署单位，并且所有的 CI/CD 都与该集群相关联，那么即使这种匹配不合适，您也会强迫每个团队遵循相同的部署流程和时间表。

以具体示例来说，假设您有一个部署到三十个集群的非常大的应用程序，以及正在开发中的一个小型新应用程序。强迫小团队立即达到大型应用程序的规模是不合理的，但如果在应用设计上过于死板，这可能正是会发生的事情。

更好的方法是将应用程序中的每个微服务在应用程序设计上视为一个面向公共的服务。虽然可能永远不会真正期望其成为公共服务，但它应该像前面部分所描述的那样拥有自己的全局负载均衡器，并且应该管理其自身的数据复制服务。在所有意图和目的上，不同的微服务应该彼此独立。当一个服务调用另一个服务时，其负载在与外部负载相同的方式下平衡。有了这种抽象，每个团队可以独立扩展和部署他们的多集群服务，就像他们在单个集群内做的那样。

当然，为应用程序中的每个微服务都这样做可能会给您的团队带来重大负担，并且可能会通过每个服务的负载均衡器维护以及可能的跨区域网络流量增加成本。像软件设计中的一切一样，复杂性与性能之间存在权衡，您需要确定适合您的应用程序在哪些地方增加服务边界的隔离，并且在何处将服务组合成复制的隔离空间是有意义的。就像单集群上下文中的微服务一样，这种设计很可能随着应用程序的变化和增长而变化和适应。期望（并设计）这种流动性将有助于确保您的应用程序可以适应而无需进行大规模的重构。

# 概要

尽管将您的应用程序部署到多个集群会增加复杂性，但现实世界中的需求和用户期望使这种复杂性对于大多数您构建的应用程序都是必要的。从头开始设计您的应用程序和基础设施以支持多集群应用程序部署将极大地增强您的应用程序的可靠性，并显著降低应用程序增长时重构的概率。多集群部署的最重要部分之一是管理应用程序的配置和部署到集群。无论您的应用程序是区域性的还是多集群的，下一章将帮助确保您能够快速和可靠地部署它。
